```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

# Classificação Avançada

## Visão Geral
Esta seção cobre métodos avançados para classificação: redes neurais, SVM, ensembles, seleção de atributos e tópicos como desbalanceamento, multiclasse, semi-supervisão e transferência.  
Slides: 1–45.

## Como ler este roteiro
Estratégia sugerida:
1. compare famílias de modelos (margem, árvores, redes e ensembles);
2. avalie impacto de seleção de atributos;
3. analise cenários especiais (desbalanceamento, semi-supervisão e transferência).
O foco é ganho preditivo com generalização.

## Configuração

Além da preparação de treino/teste, esta seção define um helper de avaliação robusto.

### Como funciona o `eval_model()`
O helper existe porque modelos diferentes podem retornar previsões em formatos distintos (rótulos, fatores, matrizes de scores/probabilidades).
Fluxo interno:
1. tenta `evaluate()` diretamente;
2. se não houver métricas, padroniza o formato da predição;
3. usa classificador proxy para reavaliar;
4. imprime métricas em treino e teste no mesmo padrão.

```{r}
# Slides 1–3: contexto
library(daltoolbox)
library(nnet)
library(ipred)
library(randomForest)
library(e1071)
library(glmnet)
library(rpart)
library(adabag)
library(xgboost)

# Conjunto de dados base
iris <- datasets::iris
head(iris)

# Preparacao treino/teste
set.seed(1)
split_random <- sample_random()
split_random <- train_test(split_random, iris)
iris_train <- split_random$train
iris_test <- split_random$test
slevels <- levels(iris$Species)

# Helper: avaliacao DALToolbox
# Slides 20–24: avaliacao comparativa

eval_model <- function(model, train, test, target_col) {
  evaluate_safe <- function(data, prediction, target_col) {
    # Padroniza alvo real para o formato esperado
    predictand <- adjust_class_label(data[, target_col])
    eval <- evaluate(model, predictand, prediction)

    # Caminho alternativo para saidas nao padronizadas
    if (is.null(eval) || is.null(eval$metrics)) {
      proxy <- classification(target_col, colnames(predictand))

      # Caso 1: previsao em vetor/fator
      if (is.factor(prediction) || is.character(prediction) || is.vector(prediction)) {
        pred <- factor(as.vector(prediction), levels = colnames(predictand))
        prediction <- adjust_class_label(pred)
      } else {
        # Caso 2: previsao matricial (escores/probabilidades)
        prediction <- as.matrix(prediction)
        if (is.null(colnames(prediction))) {
          colnames(prediction) <- colnames(predictand)[seq_len(ncol(prediction))]
        }
        # Alinha classes previstas com classes observadas
        aligned <- matrix(0, nrow(prediction), ncol(predictand))
        colnames(aligned) <- colnames(predictand)
        common <- intersect(colnames(prediction), colnames(predictand))
        aligned[, common] <- prediction[, common, drop = FALSE]
        prediction <- aligned
      }

      eval <- evaluate(proxy, predictand, prediction)
    }

    list(eval = eval, predictand = predictand)
  }

  train_prediction <- predict(model, train)
  train_res <- evaluate_safe(train, train_prediction, target_col)
  print(train_res$eval$metrics)

  test_prediction <- predict(model, test)
  test_res <- evaluate_safe(test, test_prediction, target_col)
  print(test_res$eval$metrics)

  list(
    train_prediction = train_prediction,
    train_predictand = train_res$predictand,
    test_prediction = test_prediction,
    test_predictand = test_res$predictand
  )
}
```

## Redes Neurais (MLP)
Redes feed-forward multicamadas modelam relações não lineares e podem atuar como classificadores potentes, ajustando pesos via backpropagation.  
Slides: 2–8.

Observe aqui a diferença entre métricas de treino e teste para monitorar possível sobreajuste.

```{r}
# Slides 2–8: MLP
model_mlp <- cla_mlp("Species", slevels, size = 3, decay = 0.03)
model_mlp <- fit(model_mlp, iris_train)
res_mlp <- eval_model(model_mlp, iris_train, iris_test, "Species")
```

## Maquinas de Vetores de Suporte (SVM)
SVMs buscam hiperplanos de margem máxima e usam kernels para separação não linear em espaços de alta dimensionalidade.  
Slides: 9–19.

Na prática, `cost` (e kernel) concentram parte importante do ajuste de desempenho.

```{r}
# Slides 9–19: SVM
model_svm <- cla_svm("Species", slevels, epsilon = 0.0, cost = 20.000)
model_svm <- fit(model_svm, iris_train)
res_svm <- eval_model(model_svm, iris_train, iris_test, "Species")
```

## Ensembles
Métodos ensemble combinam modelos para reduzir variância e melhorar desempenho. Bagging agrega vários modelos treinados em amostras bootstrap; Random Forest introduz aleatoriedade adicional na seleção de atributos.  
Slides: 20–24.

Leia os resultados comparando estabilidade e desempenho em teste entre os dois métodos.

```{r}
# Slides 20–24: Bagging e Random Forest
# Bagging com arvores (ipred)
set.seed(1)
model_bag <- cla_bagging("Species", nbagg = 25)
model_bag <- fit(model_bag, iris_train)
res_bag <- eval_model(model_bag, iris_train, iris_test, "Species")

# Random Forest (daltoolbox)
model_rf <- cla_rf("Species", slevels, mtry = 3, ntree = 50)
model_rf <- fit(model_rf, iris_train)
res_rf <- eval_model(model_rf, iris_train, iris_test, "Species")
```

## Boosting
Boosting combina modelos fracos sequencialmente, enfatizando exemplos difíceis em iterações posteriores.  
Slides: 25.

```{r}
# Slide 25: Boosting
set.seed(1)
model_boost <- cla_boosting("Species", mfinal = 50)
model_boost <- fit(model_boost, iris_train)
res_boost <- eval_model(model_boost, iris_train, iris_test, "Species")
```

## XGBoost
XGBoost é um método de boosting eficiente baseado em árvores.  
Slides: 25.

```{r}
# XGBoost (daltoolbox)
model_xgb <- cla_xgboost("Species", nrounds = 20)
model_xgb <- fit(model_xgb, iris_train)
res_xgb <- eval_model(model_xgb, iris_train, iris_test, "Species")
```

## Seleção de Atributos
Em alta dimensionalidade, selecionar atributos relevantes melhora generalização e interpretabilidade.  
Slides: 26–36.

Aqui combinamos abordagens complementares:
1. filtro (information gain/correlação);
2. wrapper (stepwise);
3. regularização (lasso);
4. método baseado em instâncias (relief).

```{r}
# Slides 26–36: selecao de atributos
# Conjunto de dados binario para alguns metodos
tr_fg_bin <- feature_generation(
  IsVersicolor = ifelse(Species == "versicolor", "versicolor", "not_versicolor")
)
iris_bin <- transform(tr_fg_bin, iris)
iris_bin$IsVersicolor <- factor(iris_bin$IsVersicolor)
pred_cols <- c("Sepal.Length", "Sepal.Width", "Petal.Length", "Petal.Width")

# Slide 32: Information Gain
fs_ig <- feature_selection_info_gain(
  attribute = "IsVersicolor",
  features = pred_cols,
  top = 4,
  bins = 3
)
fs_ig <- fit(fs_ig, iris_bin)
fs_ig$ranking
fs_ig$selected
iris_ig <- transform(fs_ig, iris_bin)
names(iris_ig)

No stepwise, acompanhe o compromisso entre parcimônia e poder explicativo.

# Slide 33: Forward Stepwise Selection (glm binario)
fs_step <- feature_selection_stepwise(
  attribute = "IsVersicolor",
  features = pred_cols,
  direction = "forward",
  family = stats::binomial,
  trace = 0
)
fs_step <- fit(fs_step, iris_bin)
fs_step$selected
summary(fs_step$model)

No lasso, coeficientes zerados indicam variáveis descartadas pela penalização.

# Slide 34: LASSO (glmnet)
iris_lasso <- iris_bin[, c(pred_cols, "IsVersicolor")]
iris_lasso$IsVersicolor <- factor(iris_lasso$IsVersicolor)
set.seed(1)
model_lasso <- cla_glmnet("IsVersicolor", lambda = "lambda.min")
model_lasso <- fit(model_lasso, iris_lasso)
coef_lasso <- coef(model_lasso$model, s = "lambda.min")
coef_lasso
lasso_selected <- rownames(coef_lasso)[as.vector(coef_lasso != 0)]
lasso_selected <- setdiff(lasso_selected, "(Intercept)")
lasso_selected

Em CFS, a ideia é manter atributos correlacionados com o alvo, evitando redundância entre eles.

# Slide 35: CFS (correlation-based)
fs_corr <- feature_selection_corr(
  cutoff = 0.9,
  features = pred_cols,
  keep = "IsVersicolor"
)
fs_corr <- fit(fs_corr, iris_bin)
fs_corr$selected
iris_corr <- transform(fs_corr, iris_bin)
names(iris_corr)

No RELIEF, o ranking reflete capacidade discriminativa por vizinhança.

# Slide 36: RELIEF (binario)
fs_relief <- feature_selection_relief(
  attribute = "IsVersicolor",
  features = pred_cols,
  top = 4,
  m = 50,
  seed = 1
)
fs_relief <- fit(fs_relief, iris_bin)
fs_relief$ranking
fs_relief$selected
iris_relief <- transform(fs_relief, iris_bin)
names(iris_relief)
```

## Tópicos Avançados
Inclui desbalanceamento, multiclasse, semi-supervisão e transferência.  
Slides: 37–43.

Leitura sugerida:
1. desbalanceamento: efeito da reamostragem;
2. semi-supervisão: ganho com pseudo-rótulos;
3. transferência: comparação entre modelo prévio e ajuste fino.

```{r}
# Slides 37–40: topicos avancados
# Imbalanced: downsample simples
sb_down <- sample_balance("IsVersicolor", method = "down", seed = 1)
iris_bal <- transform(sb_down, iris_bin)

bal_glm <- glm(IsVersicolor ~ Petal.Length + Petal.Width, data = iris_bal, family = binomial)
summary(bal_glm)

# Multiclasse: modelo multinomial (nnet)
multinom_model <- cla_multinom("Species")
multinom_model <- fit(multinom_model, iris_train)
multinom_pred <- predict(multinom_model, iris_test)
mean(multinom_pred == iris_test$Species)

# Slide 41: semi-supervisionado (pseudo-label simples)
set.seed(1)
mask <- sample(seq_len(nrow(iris_train)), size = floor(0.5 * nrow(iris_train)))
semi_train <- iris_train
semi_train$Species[mask] <- NA

labeled <- semi_train[!is.na(semi_train$Species), ]
unlabeled <- semi_train[is.na(semi_train$Species), ]

semi_model <- cla_multinom("Species")
semi_model <- fit(semi_model, labeled)
probs <- stats::predict(semi_model$model, unlabeled, type = "probs")
pseudo <- colnames(probs)[apply(probs, 1, which.max)]
# adiciona pseudo-rotulos
unlabeled$Species <- factor(pseudo, levels = levels(iris$Species))
semi_aug <- rbind(labeled, unlabeled)

semi_model2 <- cla_multinom("Species")
semi_model2 <- fit(semi_model2, semi_aug)
semi_pred <- predict(semi_model2, iris_test)
mean(semi_pred == iris_test$Species)

# Slides 42–43: Transfer Learning (exemplo conceitual)
# Reuso de um modelo treinado (ajuste fino com subconjunto)
pre_model <- cla_multinom("Species")
pre_model <- fit(pre_model, iris_train)

fine_idx <- sample(seq_len(nrow(iris_train)), size = 20)
fine_train <- iris_train[fine_idx, ]

fine_model <- cla_multinom("Species")
fine_model <- fit(fine_model, fine_train)

pre_pred <- predict(pre_model, iris_test)
fine_pred <- predict(fine_model, iris_test)

mean(pre_pred == iris_test$Species)
mean(fine_pred == iris_test$Species)
```

## Referências
- Han, J., Pei, J., & Tong, H. (2022). *Data Mining: Concepts and Techniques* (4th ed.). Morgan Kaufmann.
- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.
- Cortes, C., & Vapnik, V. (1995). Support-Vector Networks. *Machine Learning*, 20(3), 273–297.
- Breiman, L. (1996). Bagging predictors. *Machine Learning*, 24(2), 123–140.
- Breiman, L. (2001). Random Forests. *Machine Learning*, 45(1), 5–32.
- Freund, Y., & Schapire, R. (1997). A decision-theoretic generalization of on-line learning and an application to boosting. *Journal of Computer and System Sciences*, 55(1), 119–139.
- Tibshirani, R. (1996). Regression shrinkage and selection via the Lasso. *Journal of the Royal Statistical Society B*, 58(1), 267–288.
- Kohavi, R. (1995). A study of cross-validation and bootstrap for accuracy estimation and model selection. *IJCAI*.
